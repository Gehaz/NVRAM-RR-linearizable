
\section{Model and Definitions}
\label{section: Model}

\subsection{Standard Shared-Memory Model}

We use a standard model, based on Herlihy and Wing's model \cite{herlihyWingLinearizability}, of an asynchronous shared memory system. A set $P$ of $n > 1$ \textit{processes} $p_0, \ldots, p_{n-1}$ communicate by applying operations on shared \textit{base objects} that support atomic operations, e.g., reads, writes and read-modify-write, to shared variables. No bound is assumed on the size of a shared variable (i.e., the number of distinct values it can take).
Base objects are used in order to construct more complex implemented objects, such as queues and stacks, by defining access procedures that simulate each operation on the implemented object using operations on base objects.

The interaction of processes with implemented objects is modelled using steps and histories. There are four types of steps:
\begin{inparaenum}[(1)]
	\item an invocation step, denoted $(INV, p, X, op)$, represents the invocation by process $p$ of an operation $op$ on implemented object $X$;
	\item a response step, denoted $(RES, p, X, ret)$, represents the completion by process $p$ of the last operation it invoked on object $X$, with response $ret$;
	\item a crash step, denoted $(CRASH, p)$, represents the crash of a processes $p$;
%	\item a recovery step, denoted $(REC, p)$, represents the recovery of a process $p$. This step is the only one allowed by $p$ after a $(CRASH, p)$ step.
\end{inparaenum}

A \textit{history} $H$ is a sequence of steps. Given a history $H$, we use $H | p$ to denote the subhistory of $H$ containing all and only the events performed by process $p$. Similarly, $H | O$ denotes the subhistory of $H$ containing all and only the events performed on object $O$, plus crash and recovery events.
A response step is \textit{matching} with respect to an invocation step $s$ by a process $p$ on object $X$ in a history $H$ if it is the first response step by $p$ on $X$ that follows $s$ in $H$, and it occurs before $p$'s next invocation (if any) in $H$.

Given a history $H$ and a process $p$, an \textit{operation} by $p$ in $H$ comprises an invocation step and its matching response, if it exists. An operation is \textit{complete} if it has a matching response step, and \textit{pending} otherwise. Given two operations $op_1$ and $op_2$ in a history $H$, we say that $op_1$ \textit{happens before} $op_2$, denoted by $op_1 <_H op_2$, if $op_1$ has a matching
response that precedes the invocation step of $op_2$ in $H$. If neither $op_1 <_H op_2$ nor $op_2 <_H op_1$ holds then we say that $op_1$ and $op_2$ are \textit{concurrent} in $H$.

A history $H$ is \textit{sequential} if no two operations in it are concurrent. Two histories $H$ and $H'$ are \textit{equivalent} if for every process $p$, $H|p = H'|p$ holds. A history $H$ is \textit{well-formed} if for each process $p$, each invocation step in $H|p$ is immediately followed by a matching response, or by a crash step, and every response step in $H|p$ is a matching response for a preceded invocation. Informally, $H$ is well-formed if $H|p$ is a sequential history of operations, except for the ones that may not have a response step due to crash steps.

An object $O$ is defined using a \textit{sequential specification} which defines its allowed behaviors and is expressed as a set of possible sequential histories over $O$. A sequential history $H$ is legal if for every implemented object $O$ accessed in $H$, $H|O$ belongs to the sequential specification of $O$.


\subsubsection{Correcntess Conditions}
We now consider different variants of correctness conditions for NVRAM systems which takes into consideration failures. We follow Berryhill et al. \cite{DBLP:conf/opodis/BerryhillGT15} for formal definitions. For each variant, given a history $H$, we first define a way to extend $H$ such that some pending operations are supplied with a matching response, and the rest pending operations are removed, followed by a definition containing requirements from the resulted extension.

All the following variants are in some sense a natural extension for the Herlihy and Wing's linearizability property, since it is widely used in conventional shared memory models. As such, we first give a formal definition for linearizability. However, linearizability does not support crash steps, and therefore the definition is valid for history $H$ which is free of crash steps. Given such a history $H$, a \textit{completion} of $H$ is a history $H'$ constructed from $H$ by appending matching responses for a subset of pending operations, and then removing any remaining pending operations.

\begin{definition} [Linearizability]
	\label{Definition: Linearizability}
	A finite history $H$ is linearizable if it has no crash events, and it has a completion $H'$ and there exists a legal sequential history $S$ such that:
	\begin{enumerate}
		\item [L1.] $H'$ is equivalent to $S$; and
		\item [L2.] $<_H \subseteq <_S$ (i.e., if $op_1 <_H op_2$ and both ops appear in $S$ then $op_1 <_S op_2$).
	\end{enumerate}
\end{definition}

For strict linearizability, a \textit{strict completion} of $H$ is a history $H'$ constructed from $H$ by inserting matching responses for a subset of pending operations after the operation’s invocation and before the next crash step (if any), and finally removing any remaining pending operations and crash steps.

\begin{definition} [Strict linearizability]
	\label{Definition: Strict linearizability} 
	A finite history $H$ is strictly linearizable if it has a strict completion $H'$ and there exists a legal sequential history $S$ such that:
	\begin{enumerate}
		\item [SL1.] $H'$ is equivalent to $S$; and
		\item [SL2.] $<_{H'} \subseteq <_S$ (i.e., if $op_1 <_{H'} op_2$ and both ops appear in $S$ then $op_1 <_S op_2$).
	\end{enumerate}
\end{definition}

For persistent linearizability, a \textit{persistent completion} of $H$ is a history $H'$ constructed from $H$ by inserting matching responses for a subset of pending operations after the operation’s invocation and before the next invocation step of the same process, and finally removing any remaining pending operations and crash steps.

\begin{definition} [Persistent linearizability]
	\label{Definition: Persistent linearizability}
	A finite history $H$ is persistently linearizable if it has a persistent completion $H'$ and there exists a legal sequential history $S$ such that both conditions SL1 and SL2 of definition \ref{Definition: Strict linearizability} holds.
\end{definition}


For recoverable linearizability, a \textit{recoverable completion} $H'$ is obtained from $H$ in exactly the same manner as a strict completion. In addition, the \textit{invoked before} relation over a history $H$, denoted $\ll_H$ is an extension of the "happens before" relation, such that $op_1 \ll_H op_2$ if $op_1 <_H op_2$ or that both operations invoked by the same process $p$ on the same object $X$, and the invocation step of $op_1$ precedes the invocation step of $op_2$ in $H$. Notice that the extension takes into account pending operations, while $<_H$ is not defined in such a case.

\begin{definition} [Recoverable linearizability]
	\label{Definition: Recoverable linearizability}
	A finite history $H$ is recoverable linearizable if it has a recoverable completion $H'$ and there exists a legal sequential history $S$ such that:
	\begin{enumerate}
		\item [RL1.] $H'$ is equivalent to $S$; and
		\item [RL2.] $\ll_H \subseteq <_S$ (i.e., if $op_1 \ll_H op_2$ and both ops appear in $S$ then $op_1 <_S op_2$).
	\end{enumerate}
\end{definition}

As shown by Berryhill et al. \cite{DBLP:conf/opodis/BerryhillGT15}, the requirement for a strict completion $H'$ does not prevent an operation from taking effect after a crash that interrupts it. This follows from the fact that unlike strict linearizability, we do not ask the sequential history $S$ to respect the order $<_{H'}$, but rather the order $<_H$. For an operation $op$ that was interrupt by a crash, in $<_H$ it is after any operation that was complete before the invocation of $op$, but there is no operation following $op$ in $<_H$, since it has no response. Therefore, in $S$ we allow to place $op$ anywhere after its invocation without violating $<_H$. However, in order to prevent program order inversion of the same process on the same object, $\ll_H$ restrict $S$ not place $op$ in such a reverse order.



\subsubsection{Recoverable Response Linearizability}
As discussed in the introduction, none of the above definitions guarantee a failing process can complete its pending operation upon recovery, or at least have an access to the response value of the operation in case it is linearized. In some cases, a process might be able to know whether the operation took effect. Friedman et al. \cite{DBLP:conf/wdag/FriedmanHMP17} used the term \textit{detectable execution} for an implementation which satisfy this condition. Quoting from \cite{DBLP:conf/wdag/FriedmanHMP17}: "Durable linearizability does not provide a mechanism to determine whether an operation that executed concurrently with a crash was eventually executed. Without the ability to distinguish completed operations from lost operations, it would be difficult to recover the entire program, because in practice it is often important to execute each operation exactly once."

A concurrent object is called \textit{recoverable} if it implements a \texttt{Recover} function, such that if a process crash while executing an operation on the recoverable object, upon recovering the \texttt{Recover} function is triggered (by the system), and we require the process to complete its pending operation before invoking the next one. As we explain later, the completion requirement, although seems too restrictive, does not rule out an option for the \texttt{Recover} function to abort the pending operation, as in such case the process can reissue it. Nevertheless, this restriction simplifies the definition and proofs.

Recoverable object by its own does not consider the response value of the operation. For example, a primitive CAS is a recoverable object (with an empty \texttt{Recover} function), although a process crashing after executing CAS have no access to the response value upon recovery, as it was lost. For this reason we extend the definition of recoverable object, such that in addition to a \texttt{Recover} function it also needs to satisfy the following: every operation returns (i.e., there is a response step in the history) only after the response value is persistent. In a more formal way, a process $p$ have a designated variable $Res_p$ in the non-volatile memory such that at the time of $(RES,p,X,ret)$ step, the value $ret$ is written in $Res_p$.
Notice that the object's semantic does not change, that is, we do not require the response value to be persistent at the linearization point.

A recoverable object is in some sense "fail-resistant". If a process crash after completing an operation, then upon recovery the process have an access to the response value residing in the non-volatile memory. On the other hand, if a process crash before the response value is persistent, i.e., before the operation was completed, then upon recovery the \texttt{Recovery} function will complete the operation, together with making the response value persistent. To our knowledge, this is the first definition to consider the affect of a crash on the crashing process, and not only on the object.

One can think of different ways to persist the response value. For example, an operation to a recoverable object gets a location in the shared memory as an extra operand, and the response value is persistent in this location at the response step. This can be implemented easily by replacing $Res_p$ with the supplied location. We do not role out such solutions. However, for ease of presentation the definition uses a simple version.

Notice that any object can be implemented in a recoverable manner, as long as there is no restriction on the correctness condition it requires to satisfy. The \texttt{Recover} function does not allow a process $p$ to invoke a new operation before completing the pending operation, hence in every history $H$ a process have at most a single pending operation which is his last invoked operation. Therefore a natural requirement for such an object is linearizability. Since every operation of a process needs to be complete (except for maybe the last one), and we use the original definition of linearizability, this implies that locality holds under this definition.

\begin{definition} [Recoverable response linearizability]
	\label{Definition: RR-linearizability}
	A finite history $H$ is recoverable response linearizable if it contains operations to recoverable objects only and $H$ is linearizable.
\end{definition}

