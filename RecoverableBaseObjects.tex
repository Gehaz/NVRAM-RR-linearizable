
\section{Recoverable Base Objects}
\label{section: Recoverable Base Objects}

In this section, we present algorithms for recoverable base objects that support primitive operations such as read, write, compare-and-swap (CAS) and test-and-set. As described in Section \ref{section: Model}, this consists in implementing a recovery function $Op.\texttt{Recover}$ for each such operation, which is invoked by the system upon a crash-failure when $Op$ is the crashed operation. In the pseudo-code, we use names that start with a capital letter for shared-memory variables and lower-case names for local variables. We also use capital-letter names for implemented operations and lower-case names for primitive operation names.
%\emph{All the shared-memory variables used by our algorithms are non-volatile}.

In this paper, we only consider recoverable objects or base objects provided by the system that support atomic read, write or read-modify-write (RMW) operations. Before presenting our algorithms we prove that, under these assumptions, our model guarantees that all histories are recoverable well-formed.

\begin{lemma}
\label{all-histories-well-formed}
Let $H$ be a history in which all operations are applied to either recoverable objects or atomic base objects. Then $H$ is recoverable well-formed.
\end{lemma}
\begin{proof}
Consider an execution $\alpha$ of any algorithm and the corresponding history $H(\alpha)$.
If an atomic read, write or RMW is executed in $\alpha$, then its invocation and response steps appear in $H$ consecutively hence cannot violate well-formedness, so it suffices to consider invocation/response steps on recoverable objects and crash/recovery steps.

When a process $p$ invokes an operation $Op$ on a recoverable object $O$, a corresponding invocation step $i$ is appended to $H(\alpha)$. If $p$ crash-fails inside $Op$, a $(CRASH, p)$ step $c$ is appended to $H(\alpha)$ and its crashed operation is $Op$. The system eventually resurrects $p$ and invokes $Op.\texttt{RECOVER}$, thus a recovery step $r$ that matches $c$ is appended to $H(\alpha)$ . If $p$ undergoes additional failures before $Op$ completes, then additional pairs of a crash step and its matching recovery step are appended to $H(\alpha)$. Otherwise, if and when $Op$ completes, a response step $r$ that matches $i$ is appended to $H(\alpha)$. It follows from Definition \ref{def:recoverable-well-formedness} that $H(\alpha)$ is a recoverable well-formed history.
\end{proof}


\paragraph*{A Recoverable Read-Write Object}

Our recoverable read-write object algorithm assumes that all values written to the object are distinct. This assumption can be easily satisfied by augmenting each written value with a tuple consisting of the writing process' ID and a per-process sequence number. In some cases, such as the example of a recoverable counter that we provide later, this assumption is satisfied due to object semantics and does not require special treatment.

Algorithm \ref{alg:recoverable-write} presents pseudo-code for process $p$ of a recoverable read-write object $R$. It supports non-strict (see Definition \ref{def:strict-recoverable-op}) recoverable \texttt{READ} and \texttt{WRITE} operations. Both \texttt{READ} and \texttt{READ.RECOVER} simply return $R$'s current value (lines \ref{read-first}-\ref{read-return}, \ref{read-recover-start}-\ref{read-recover-last}.

Our implementation of \texttt{WRITE} ``wraps'' the write primitive with code that allows the recovery function \texttt{WRITE.RECOVER} to conclude whether $p$'s write in line \ref{write-to-R}, or a write by a different process, took place since $p$'s invocation of \texttt{WRITE}. This is done using a single-reader-single-write shared-memory variable $S_p$ that stores a pair of values -- $R$'s previous value (read in line \ref{write-start}) and a flag that allows the recovery function  to infer the location in \texttt{WRITE} where the failure occurred. Specifically, $flag=0$ holds whenever $p$ is either not performing a \texttt{WRITE} operation on $R$ (since it is initialised to $0$) or $p$ has performed line \ref{write-second} but \texttt{WRITE} was not yet completed.

\begin{algorithm}
	\caption{recoverable read/write object $R$, program for process $p$}
	\label{alg:recoverable-write}
	
	\hspace*{\algorithmicindent} \textbf{Shared variables:}
	$S_p$ - pair of values, init $<0,null>$
	
	\begin{multicols}{2}
	\begin{algorithmic}[1]	
		\Procedure{\texttt{WRITE}(val)}{}
		\State $temp \gets R$ \label{write-start}
		\State $S_p \gets <1,temp>$ \label{write-first}
		\State $R \gets val$ \label{write-to-R}
		\State $S_p \gets <0,val>$ \label{write-second}
		\State \Return $ack$
		\EndProcedure

		\Procedure{\texttt{READ}()}{} \label{read-first}
        \State $temp \gets R$ \label{read-read-R}
        \State \Return $temp$ \label{read-return}
		\EndProcedure

		
		\columnbreak
		
		\Procedure{\texttt{WRITE}.\texttt{RECOVER}(val)}{}
		\State $<flag, curr> \gets S_p$ \label{write-recover:read-Sp}
		\If {$flag = 0 \land curr \neq val$} \label{write-recover:if-did-not-start}
			\State proceed from line \ref{write-start} \label{write-recover:reexecute1}
		\ElsIf {$flag = 1 \land curr = R$} \label{write-recover:read-R}
			\State proceed from line \ref{write-start}
		\EndIf
		\State $S_p \gets <0,val>$ \label{write-recover:update-Sp}
		\State \Return $ack$ \label{write-recover:return-ack}
		\EndProcedure

		\Procedure{\texttt{READ.RECOVER}() \label{read-recover-start}}{}
        \State $temp \gets R$ \label{read-recover-read-R}
        \State \Return $temp$ \label{read-recover-return}
		\EndProcedure \label{read-recover-last}
	\end{algorithmic}
\end{multicols}
\end{algorithm}



The intuition for correctness is the following. A crash before line \ref{write-first} executes implies that both $S_p = {<}0,curr{>}$ and $curr \neq val$ hold, since we assume each value written to $R$ is distinct. In this case, \texttt{WRITE.RECOVER} simply re-executes \texttt{WRITE} (lines \ref{write-recover:if-did-not-start}-\ref{write-recover:reexecute1}). A failure after line \ref{write-second} executes implies that $S_p={<}0,val{>}$ holds, in which case \texttt{WRITE.RECOVER} returns $ack$. Otherwise neither of the conditions of lines \ref{write-recover:if-did-not-start},\ref{write-recover:read-R} holds, hence either $p$ already executed line \ref{write-to-R}, or another process wrote to $R$ between when $R$ was read by $p$ in \texttt{WRITE} (line \ref{write-start}) and in \texttt{WRITE.RECOVER} (line \ref{write-recover:read-R}). In either of these cases, we may linearize \texttt{WRITE}, so the recovery function updates $S_p$ and returns \emph{ack} (lines \ref{write-recover:update-Sp}-\ref{write-recover:return-ack}). A formal correctness proof follows.

%A failure in between implies that $R_p=<1,curr>$ holds, for $curr \neq val$. Here there are two cases to consider. If there was a write to $R$ (by another process) between when $R$ was read by $p$ in \texttt{WRITE} (line \ref{write-start}) and in \texttt{WRITE.RECOVER} (line \ref{write-recover:read-R}), then either $p$ executed line \ref{write-to-R} and \texttt{WRITE} can be linearized at that point, or a write by another process occurred in between, hence we can linearize $p$'s \texttt{WRITE} immediately before it regardless of whether $p$ executed line \ref{write-recover:read-R} or not. In any case, we get $curr \neq R$, and the \texttt{Recover} function consider the operation as done.

\begin{lemma}
	Algorithm~\ref{alg:recoverable-write} satisfies CRL.
\end{lemma}

\begin{proof}
%First notice that Algorithm~\ref{alg:recoverable-write} is wait-free and has a constant time complexity for both the WRITE and the \texttt{Recover}.
First observe that $R$ is a recoverable object since each of its two operations has a corresponding \texttt{RECOVER} function. Consider an execution $\alpha$ of the algorithm and the corresponding history $H(\alpha)$. From Lemma \ref{all-histories-well-formed}, $H(\alpha)$ is recoverable well-formed. Hence, $H'(\alpha)=N(H(\alpha))$ is a well-formed (non-recoverable) history. Following definition \ref{Definition:CRL}, it is enough to prove that $H'(\alpha) | R$ is  linearizable.
	
Since neither of $R$'s recovery functions write to variables read by other processes, they have no effect on their execution. We can therefore ignore crashes that occur during the execution of the recovery functions, as long as $S_p$ is not written (which only occurs in line \ref{write-recover:update-Sp} of \texttt{WRITE.RECOVER}).

Assume $p$ applies a $\texttt{WRITE}(val)$ operation to $R$ in $\alpha$. If $p$ does not fail during its execution, then clearly $p$ writes to $R$ exactly once in line \ref{write-to-R} and this is the operation's linearization point. Otherwise, assume that $p$ fails when executing the \texttt{WRITE} operation. A crash before line \ref{write-first} implies that $p$ did not yet write to neither $S_p$ nor $R$, hence \texttt{WRITE} was not linearized yet. Upon recovery, $p$ reads $S_p={<}0,curr{>}$, where $curr \neq val$ holds, since we assume all written values are distinct. Hence, \texttt{WRITE.RECOVER} re-executes \texttt{WRITE}.

A crash between the two writes to $S_p$ (in lines \ref{write-first} and \ref{write-second}) implies that $S_p={<}1,curr{>}$ and $curr \neq val$ holds. Upon recovery, if the condition of line \ref{write-recover:read-R} is satisfied, then $curr = R$ ensures that no process wrote to $R$ between the two reads of $R$ (in lines \ref{write-start} and \ref{write-recover:read-R}). In particular, $p$ did not write to $R$ (so \texttt{WRITE} was not linearized) and the operation is re-executed.

Otherwise $curr \neq R$, i.e., there was a write to $R$ between the two reads of $R$ by $p$. If $p$ wrote to $R$ in line \ref{write-to-R}, then the operation was already linearized at this point. Else, there was a write by a different process $q$ that occurred between the two reads by $p$, hence within the execution interval of $p$'s $\texttt{WRITE}$. Thus, $p$'s $\texttt{WRITE}$ can be linearized immediately before $q$'s, causing $q$ to immediately overwrite $val$ (if it was indeed written by $p$ in line \ref{write-to-R}), resulting in an execution that is indistinguishable to all processes from one in which $p$ does not write to $R$ at all. It follows that, in both these cases, $p$'s $\texttt{WRITE}$ operation can be linearized correctly and \texttt{WRITE.RECOVER} returns $ack$.

The last case to consider is when $\texttt{WRITE.RECOVER}$ reads ${<}0,val{>}$ in line \ref{write-recover:read-Sp} and then performs lines \ref{write-recover:update-Sp}-\ref{write-recover:return-ack} and returns. This can occur either if $p$ crashed after executing line \ref{write-second}, or if it crashed before line \ref{write-second} but a subsequent  \texttt{WRITE.RECOVER} failed after updating $S_p$ (in line \ref{write-recover:update-Sp}). The latter case can happen only if a previous invocation of \texttt{WRITE.RECOVER} by $p$ read $S_p={<}1,curr{>}$, for $curr \neq R$, executed line \ref{write-recover:update-Sp} and then failed. Our previous analysis established that \texttt{WRITE} can be linearized also in this case. This concludes our discussion of linearization points of \texttt{WRITE} operations. As for \texttt{READ}, if and when it returns (in lines \ref{read-return} or \ref{read-recover-return}), it is linearized when it last read $R$ (in line \ref{read-read-R} or line \ref{read-recover-read-R}, resp.).
\end{proof}


\paragraph*{A Recoverable Compare-and-Swap Object}

A Compare-and-Swap (CAS) object supports the $\texttt{CAS}(old,new)$ operation, which atomically swaps the object's value to $new$ only if the value it stores is $old$. The operation returns true and we say it is \emph{successful} if the swap is performed, otherwise it returns false and we say it \emph{fails}. A CAS object also supports a \texttt{READ} operation which returns the object's value. Algorithm \ref{alg:recoverable-CAS} presents  pseudo-code for process $p$ of a recoverable CAS object $C$. %It supports recoverable \texttt{CAS} and \texttt{READ} operation.


$C$ stores two fields, both initially $null$. The first is the ID of the last process that performed a successful \texttt{CAS} and the second is the value it wrote. Both \texttt{READ} and \texttt{READ.RECOVER} simply return \emph{C.val}. Inside the \texttt{CAS} operation, process $p$ first reads $C$. If \emph{C.val} was written by process $q$, then $p$ stores it in $R[q,p]$ which is a SRSW shared variable used by $p$ to inform $q$. This allows processes to inform each other which \texttt{CAS} operations were successful. We assume that \texttt{CAS} is never invoked with $old=new$ and that values written to $C$ by the same process are distinct. This assumption can be easily satisfied by augmenting each written value with a per-process sequence number.

\begin{algorithm}[b]%{Compare-and-Swap}
	\caption{recoverable CAS object $C$, program for process $p$}
	\label{alg:recoverable-CAS}
	
	\hspace*{\algorithmicindent} \textbf{Shared variables:}
	R[N][N] - all elements init $null$

	\begin{multicols}{2}
	\begin{algorithmic}[1]
		\Procedure{\texttt{CAS}(old,new)}{}
		\State ${<}id,val{>} \gets C.read()$ \label{cas:start}
		\If {$val \neq old$} \label{cas:if-compare-read}
%		\State $Res_p \gets false$
		\State \Return $false$ \label{cas:return-false}
		\EndIf
		\If {$id \neq null$}
  		\State $R[id][p] \gets val$ \label{cas:write-C-value}
		\EndIf
		\State $ret \gets C.cas({<}id,va{l}>, {<}p,new{>})$ \label{cas:primitive-apply}
%		\State $Res_p \gets ret$
		\State \Return $ret$ \label{cas:operation-return}
		\EndProcedure
		
		\Procedure{\texttt{READ}()}{}
		\State ${<}id,val{>} \gets C$ \label{cas:read-start}
		\State \Return $val$ \label{cas:read-return}
		\EndProcedure
		
		\columnbreak
		
		\Procedure{\texttt{CAS.RECOVER}(old, new)}{}
%		\State Read C, R[p][$*$] \label{cas:recover-read-vars}
%		\If {$C={<}p,new{>}$, or $new$ appears in R[p][$*$]}
		\If {$C={<}p,new{>} \lor \newline \phantom{x}\hspace{4ex} new \in \{R[p][1],\ldots,R[p][N]\}$ \label{cas:recover-read-vars}}
%		\State $Res_p \gets true$
		\State \Return $true$ \label{cas:recover-returns-true}
		\Else {}
		\State proceed from line \ref{cas:start} \label{cas:recover-re-execute}
		\EndIf
		\EndProcedure
		
		\Procedure{\texttt{READ.RECOVER}()}{}
		\State ${<}id,val{>} \gets C$ \label{cas:read-recover-start}
		\State \Return $val$ \label{cas:read-recover-return}
		\EndProcedure
	\end{algorithmic}
\end{multicols}
\end{algorithm}

%The key algorithmic idea is the following.
A process $p$ first reads $C$. If it reads a value $v$ other than $old$ it returns \emph{false} and is linearized at the read. Otherwise, if $v \neq {null}$, $p$ informs the process (say, $q$) that wrote $v$ that its CAS took effect by setting $R[q][p] \gets v$.
%This way, if $p$ fails after a successful \texttt{CAS} operation, the next process to change $C$'s value, if any, will inform $p$ that its \texttt{CAS} was successful.
This mechanism guarantees that, upon recovery, process $p$ is able to determine that its \texttt{CAS} operation took effect if the value it wrote is still stored in $C$ or is written in $R[p][j]$, for some $j$.

If $p$ crash-fails inside \texttt{CAS} without modifying $C$, either because it crashes before line \ref{cas:primitive-apply} or because it crashed after its $cas$ in line \ref{cas:primitive-apply} failed, then ${<}p,new{>}$ is never written to $C$ or to any of $R[p][*]$. In this case, \texttt{CAS.RECOVER} simply re-executes  \texttt{CAS}. A key point in the correctness argument is that a \texttt{CAS} operation that crashed after a failed (primitive) \emph{cas} can be re-executed, since it did not affect other processes, hence we may assume it was not linearized yet and re-execute it without violating the sequential specification of CAS.

\begin{lemma}
\label{lemma:CAS-alg-is-CRL}
	Algorithm \ref{alg:recoverable-CAS} satisfies CRL.
\end{lemma}

\begin{proof}
	
	First observe that $C$ is a recoverable object since each of its two operations has a corresponding \texttt{RECOVER} function. Consider an execution $\alpha$ of the algorithm and the corresponding history $H(\alpha)$. From Lemma \ref{all-histories-well-formed}, $H(\alpha)$ is recoverable well-formed. Hence, $H'(\alpha)=N(H(\alpha))$ is a well-formed (non-recoverable) history. Following definition \ref{Definition:CRL}, it is enough to prove that $H'(\alpha) | C$ is  linearizable.
	Since none of the recovery functions writes to a variable read by other processes, they have no effect on their executions. We can therefore ignore crashes that occur during the execution of the recovery function.
	
	For presentation simplicity, when we refer to \emph{the value of} $C$ we refer the value of its second field, which represents the state of the object, and when refer to \emph{the content of }$C$, we refer to both fields as a pair. Since no process writes the same value twice, it follows that the content of $C$ is unique, while the values of $C$ are not necessarily unique, since different processes may write the same value.
	
	Assume $p$ applies a $\texttt{CAS}(old,new)$ operation to $C$ in $\alpha$. First assume $p$ does not crash during the \texttt{CAS} operation.
	In line \ref{cas:start}, $p$ reads $C$ and then compares the value of $C$ to $old$. If the values differ, then the operation is linearized at the read in line \ref{cas:start} and indeed at this point the value of $C$ is different from $old$, so $p$ returns $false$ in line \ref{cas:return-false}.
	Otherwise, $p$ informs the last process $q$ to have performed a successful \texttt{CAS} that its operation took effect. It does so by writing to $R[q][p]$ the value it read from $C$. A two dimensional array $R$ of SRSW registers is used for this purpose. Following that, $p$ tries to change the value of $C$ by performing $CAS$ in line \ref{cas:primitive-apply}. %Notice that $p$'s id is added, as the CAS content is composed of two fields.
	
	There are two scenarios to consider.
	Assume first there is a successful \texttt{CAS} applied to $C$ between $p$'s execution of line \ref{cas:start} and line \ref{cas:primitive-apply}. In this case, the first such operation must change $C$'s value to a value other than $old$, and we can linearize $p$'s operation right after it. Since the content of $C$ is unique, $p$'s $CAS$ in line \ref{cas:primitive-apply} fails, and it returns $false$ in line \ref{cas:operation-return}. Otherwise, there was no successful \texttt{CAS} to $C$ between the read in line \ref{cas:start} and the $CAS$ in line \ref{cas:primitive-apply}, and thus the $CAS$ in line \ref{cas:primitive-apply} is successful, and this is also the linearization point and $p$ returns $true$ in line \ref{cas:operation-return}.
	
	Assume now that $p$ crashes during a \texttt{CAS} operation.
	If $p$ did not write to $C$, either because the crash occurs before line \ref{cas:primitive-apply}, or due to a failed $CAS$ operation in line \ref{cas:primitive-apply}, then ${<}p,new{>}$ is not written to $C$. This follows from the fact that $p$ writes distinct values, thus \emph{new} was not written by $p$ before. As processes writes to $R$ only values read from $C$, no process writes \emph{new} to $R[p][*]$. As a result, \texttt{CAS.RECOVER} re-executes \texttt{CAS}. A failed CAS operation does not affect other processes, that is, removing the operation is indistinguishable to other processes. Therefore, in both cases, considering the operation as not having a linearization point so far and re-executing it does not violate the sequential specification of CAS.
	
	If $p$ did perform a successful \texttt{CAS} in line \ref{cas:primitive-apply} before the crash, then this is also the operation's linearization point. We argue that the next process $q$ to perform a successful \texttt{CAS} on $C$, if any, must write $new$ to $R[p][q]$ before its \texttt{CAS} takes effect. Assume there exists such a process $q$. Then, consider the time when the successful \texttt{CAS} of $q$ in line \ref{cas:primitive-apply} occurs. It must be that $q$ executes line \ref{cas:start} to line \ref{cas:primitive-apply} without crashing, since any crash before writing to $C$ will cause the re-execution of the \texttt{CAS} operation, as we have already shown. In addition, $q$ reads ${<}p,new{>}$ from $C$ in line \ref{cas:start}, since by our assumption it succeeds in replacing $p$'s value, that is, it performed a successful $CAS$ when $C$'s content was ${<}p,new{>}$. As the content of $C$ is unique, reading any other content implies the $CAS$ in line \ref{cas:primitive-apply} fails, a contradiction. Hence, before $q$'s successful \texttt{CAS} in line \ref{cas:primitive-apply}, it writes \emph{new} to $R[p][q]$ in line \ref{cas:write-C-value}.
	We assume that the reads in line \ref{cas:recover-read-vars} of \texttt{CAS.RECOVER} are done from left to right. As a result, in line \ref{cas:recover-read-vars}, $p$ either reads $C={<}p,new{>}$ or, otherwise, another process already replaced $C$'s content but wrote $new$ to $R[p][*]$ before that, thus $p$ observes $new$ in $R[p][*]$. In both cases, $p$ considers the \texttt{CAS} operation as successful and returns true in line \ref{cas:recover-returns-true}.
	
	As for \texttt{READ}, if and when it returns (in lines \ref{cas:read-return} or \ref{cas:read-recover-return}), it is linearized when it last read $C$ (in line \ref{cas:read-start} or line \ref{cas:read-recover-start}, resp.)
	
\end{proof}



\paragraph*{A Recoverable Test-and-Set Object}

A non-resettable Test-and-Set (TAS) object is initialized to 0 and supports the $\texttt{T\&S}$ operation. It atomically writes 1 and returns the previous value. In the following, we present a recoverable non-resettable test-and-set algorithm that uses (non-recoverable) non-resettable TAS objects and read/write shared variables. We first present an impossibility result on such implementations of recoverable TAS algorithms. We say that an operation (or a recovery function) is \emph{wait-free} \cite{herlihy91waitfree}, if a process that does not incur failures during its execution completes it in a finite number of its own steps. Our implementation of TAS has a wait-free $\texttt{T\&S}$ operation but its recovery code is blocking. The following theorem proves that this is inevitable: any recoverable TAS object from these primitives cannot have both a wait-free $\texttt{T\&S}$ operation and a wait-free $\texttt{T\&S.RECOVER}$ function.

\begin{theorem}
	There exists no recoverable non-resettable TAS algorithm satisfying CRL, from read/write and (non-recoverable) non-resettable TAS base objects only, such that both the \texttt{T\&S} operation and the \texttt{T\&S.RECOVER} function are wait-free.
\end{theorem}

\begin{proof}
	We prove the theorem using valency arguments \cite{DBLP:journals/jacm/FischerLP85}. Let $\mathcal{A}$ be a CRL recoverable non-resettable TAS implementation using the base objects assumed by the theorem, and assume towards a contradiction that both \texttt{T\&S} and \texttt{T\&S.RECOVER} are wait-free. We say that a configuration $C$ is p-valent (resp. q-valent) if there exists a crash-free execution starting from $C$ in which $p$ (resp. $q$) returns 0 or has already returned $0$. $C$ is bivalent if it is both $p$-valent and $q$-valent, and univalent otherwise. Observe that any configuration $C$ is either $p$-valent or $q$-valent (or both), because in a solo execution of $p$ followed by a solo execution of $q$ from $C$ where both complete their operations (if they haven't done so already), exactly one must return (or already returned) 0.
	
	The initial configuration $C_0$, in which both $p$ and $q$ invoke the $TAS$ operation, is bivalent -- a solo execution of each process returns 0. Using valency arguments and as we assume that \texttt{T\&S} is wait-free, there is an execution starting from $C_0$ that leads to a bivalent configuration $C_1$, in which both $p$ and $q$ are about to perform a critical step. This step must be an application of the $t\&s$ primitive to the same base object. Moreover, a step by any of the processes leads to a different univalent configuration. Assume wlog that configuration $C_1 \circ p$ is $p$-valent whereas $C_1 \circ q$ is $q$-valent.
	
	Let $p$ and then $q$ perform their next $t\&s$ steps, followed by a crash step of $p$. Since $p$'s response from the $t\&s$ primitive is lost due to the crash, upon recovery $p$ does not know whether the $t\&s$ primitive was performed, and if it was, what the response value was. Specifically, configurations $C_1 \circ p \circ q \circ CRASH_p$ and $C_1 \circ q \circ p \circ CRASH_p$ are indistinguishable to $p$. Consequently, an execution of \texttt{T\&S.RECOVER} by $p$ after both configurations (which will complete since we assume that \texttt{T\&S.RECOVER} is wait-free) returns the same value $ret$. This implies that both configurations are $u$-valent for some $u$.
	
	Wlog assume $u=p$ (the other case is symmetric), then we consider configuration $C'_1=C_1 \circ q \circ p \circ CRASH_p$. Note that $C'_1$ is indistinguishable from configuration $C_1 \circ q \circ p$ for $q$, since $q$ is not aware of $p$'s crash. Therefore, $C'_1$ is both $q$-valent and $p$-valent, that is, it is bivalent. Since we assume that both processes are only allowed to use read, write and t\&s primitives, we can repeat the same argument again and show that there is an extension of $C'_1$ leading to a bivalent configuration $C_2$, where both $p$ and $q$ are about to perform a critical step. Moreover, this step must be the application of a t\&s primitive to the same base object. This must be a TAS base object other than those previously used in the execution, since those would always return 1, contradicting criticality.
	
Continuing in this manner, we construct a crash-free execution of $q$ in which it executes an infinite number of steps while performing a single \texttt{T\&S} operation. This is a contradiction.
\end{proof}

Algorithm \ref{alg:recoverable-TAS} presents a pseudo-code for process $p$ of a recoverable TAS object $T$. It supports strict recoverable \texttt{T\&S} operation.
For simplicity we allow a process to return $true$ or $false$, representing $0$ and $1$ resp. We assume a process invoke \texttt{T\&S} operation at most once, as any additional operation returns 1.


\begin{algorithm}[b]%{Test-and-Set}
	\caption{recoverable TAS object $T$, program for process $p$}
	\label{alg:recoverable-TAS}
	
	\hspace*{\algorithmicindent} \textbf{Shared variables:}
	\begin{itemize}[noitemsep,topsep=0pt]
		\item R[N]: an array, init $[0,\ldots,0]$
		\item Winner, Doorway: read/write registers, init $null$, $true$ resp.
	\end{itemize}
	
	\begin{multicols}{2}
		\begin{algorithmic}[1]
			\Procedure{\texttt{T\&S}()}{}
			\State $R[p] \gets 1$ \label{tas:start}
			\If {$Doorway = false$} \label{tas:check-doorway}
			\State $ret \gets 1$ \label{tas:doorway-return-1}
			\State proceed from line \ref{tas:return-code}
			\EndIf
			\State $R[p] \gets 2$ \label{tas:set-R[p]-2}
			\State $Doorway \gets false$ \label{tas:close-doorway}
			\State $ret \gets T.t\&s()$ \label{tas:tas-primitive}
			\If {$ret = 0$}
			\State $Winner \gets p$ \label{tas:write-to-winner}
			\EndIf
			\State $Res_p \gets ret$ \label{tas:return-code}
			\State $R[p] \gets 3$ \label{tas:set-R[p]-3}
			\State \Return $ret$
			\EndProcedure
			
			\columnbreak
			
			\Procedure{\texttt{T\&S.RECOVER}()}{}
			\If {$R[p] < 2$} \label{tas:rec:start}
			\State proceed from line \ref{tas:start}
			\EndIf
			%	\If {$Doorway = true$}
			%		\State proceed from line \ref{tas:close-doorway}
			%	\EndIf
			\If {$R[p] = 3$} \label{tas:rec:return-operation-done}
			\State $ret \gets Res_p$
			\State \Return $ret$
			\EndIf
			\If {$Winner \neq null$} \label{tas:rec:check-winner}
			\State proceed from line \ref{tas:rec:return-code}
			\EndIf
			\State $Doorway \gets false$ \label{tas:rec:close-doorway}
			\State $R[p] \gets 4$ \label{tas:rec:set-R[p]-4}
			\State $T.t\&s()$ \label{tas:rec:tas-primitive}
			\For {$i$ from $0$ to $p-1$} \label{tas:rec:wait-lower-id}
			\State await($R[p] = 0$ or $R[p] = 3$)
			\EndFor
			\For {$i$ from $p+1$ to $N$} \label{tas:rec:wait-higher-id}
			\State await($R[p] = 0$ or $R[p]>2$)
			\EndFor
			\If {$Winner = null$} \label{tas:rec:winner-not-overwrite}
			\State $Winner \gets p$ \label{tas:rec:write-winner}
			\EndIf
			\State $ret \gets (Winner \neq p)$ \label{tas:rec:return-code}
			\State $Res_p \gets ret$
			\State $R[p] \gets 3$ \label{tas:rec:set-R[p]-3}
			\State \Return $ret$
			\EndProcedure
		\end{algorithmic}
	\end{multicols}
\end{algorithm}


A doorway mechanism is used to guarantee once a process sets the doorway all operations invoke later returns 1. This implies a operation which returns 0 can be linearized before any other operation. The doorway can be replaced with reading $T$ in line \ref{tas:check-doorway}, in case of a TAS object which supports also a read operation.
After passing the doorway, a process tries to win the TAS object in line \ref{tas:tas-primitive}, and the winning process declare itself by writing to a designated variable $Winner$. Once a process writes to $Winner$ any process can recover by simply read $Winner$. Hence, the main difficulty is to make sure a single process writes to $Winner$.

A crash before line \ref{tas:set-R[p]-2} executes implies the operation did not affect any other process so far, and \texttt{T\&S.RECOVER} re-executes \texttt{T\&S}. A crash after setting $R[p] \gets 3$, in either line \ref{tas:set-R[p]-3} or \ref{tas:rec:set-R[p]-3} implies $p$ already computed its response and wrote it to $Res_p$. In such case, \texttt{T\&S.RECOVER} simply copy the response from $Res_p$ and return it. A crash after a process wrote to $Winner$ implies a winner declare itself, thus in \texttt{T\&S.RECOVER} $p$ check to see if it is the winner and answer accordingly.

If none of the above cases holds, this means $p$ is still competing to win the TAS. Therefore, it closes the doorway in line \ref{tas:rec:close-doorway}, in case it is still open, and announce it is competing for the TAS in \texttt{T\&S.RECOVER} by writing 4 to $R[p]$ in line \ref{tas:rec:set-R[p]-4}. Following that, it has to pass two for loops in lines \ref{tas:rec:wait-lower-id} and \ref{tas:rec:wait-higher-id}. In the first one it waits for any running process with lower id to complete its operation. In the later, it waits for any running process with higher id to either complete or announce itself as recovering.
The for loops grantee that if there is a process writing to $Winner$ in line \ref{tas:write-to-winner}, then $p$ must wait for it to do so. Also, only the smallest id process that is competing to win the TAS and crash can complete the two for loops and write to $Winner$ in line \ref{tas:rec:write-winner}, while the rest must wait for it to complete. This implies at most a single process writes to $Winner$, and eventually one must do so. As argued before, once a process writes to $Winner$, upon completing its operation it returns 0.



\begin{claim}
	Algorithm \ref{alg:recoverable-TAS} satisfies CRL.
\end{claim}

\begin{proof}
	
	First observe that $T$ is a recoverable object since each of its two operations has a corresponding \texttt{RECOVER} function. Consider an execution $\alpha$ of the algorithm and the corresponding history $H(\alpha)$. From Lemma \ref{all-histories-well-formed}, $H(\alpha)$ is recoverable well-formed. Hence, $H'(\alpha)=N(H(\alpha))$ is a well-formed (non-recoverable) history. Following definition \ref{Definition:CRL}, it is enough to prove that $H'(\alpha) | T$ is  linearizable.
	
	The proof relies on the following simple observations:
	\begin{enumerate} [noitemsep,topsep=0pt]
		\item In any execution where there is a process completing its operation, there must be a write to $Doorway$.
		\item Once a process writes to $Doorway$, any operation yet to execute line \ref{tas:start} returns 1 if given enough time with no crash. Moreover, such an operation can set $R[p]$ to either 1 or 3.
		\item Once a process writes 3 to $R[p]$ (in line \ref{tas:set-R[p]-3} or \ref{tas:rec:set-R[p]-3}), its response is persistent in $Res_p$. In addition, $R[p]$ is fixed for the rest of the execution, and if $p$ given enough time with no crash it returns the value stored in $Res_p$.
		\item A process which returns 0 must also write to $Winner$.
		\item Assume a process $p$ writes to $Winner$, and it is the only process to do so. Then if given enough time with no crash $p$ eventually returns 0.
	\end{enumerate}
	
	
	
	If no \texttt{T\&S} operation completes in $\alpha$, then $H'$ is obviously linearizable. Thus, assume there is a complete \texttt{T\&S} operation, either normally or by completing a \texttt{T\&S.RECOVER} execution. Denote by $t$ the time of the first write to $Doorway$. There is no operation complete before time $t$, otherwise there is an earlier write to $Doorway$, in contradiction. Also, any operation yet to execute line \ref{tas:start} at time $t$ returns 1 (if it returns), and can set $R[p]$ to either 1 or 3.
	%In addition, any operation is before executing line \ref{tas:write-to-winner} or \ref{tas:rec:write-winner} at time $t$ by definition. In particular, there is no operation that was completed before time $t$.
	
	
	The proof composed of two claims - there can be no two operations returning 0, and if the entire system is given enough time with no crash there must be such an operation. It follows that either there is a single operation pending at time $t$ which returns 0 in $\alpha$, or there is no such operation, but there is a pending operation at time $t$ that is yet to complete in $\alpha$. In both cases we can linearize one operation at time $t$ as returning 0, while the rest can be linearize after it, and they all return 1. This proves $H'$ is linearizable.
	
	Following the observations it suffices to prove there can be no two processes writing to $Winner$.
	Assume there is a process $p$ writing to $Winner$ in line \ref{tas:write-to-winner}. Then, no other process can write to $Winner$ in line \ref{tas:write-to-winner}, since T returns 0 exactly once.
	Assume towards a contradiction there exists a process $q$ writing to $Winner$ in line \ref{tas:rec:write-winner}. Then, $q$ is before executing line \ref{tas:rec:set-R[p]-4} at time $t$ by definition. In order to write to $Winner$ it has to go through the for loops in the \texttt{T\&S.RECOVER} function, and thus have to wait for $p$ to set $R[p] > 2$ in any case. By the observations, at time $t$ $p$ is after executing line \ref{tas:start}. Also, $p$ can not set $R[p]$ to 4 in line \ref{tas:rec:set-R[p]-4}, as this implies $p$ crash after executing line \ref{tas:set-R[p]-2} and before writing to $Winner$, and in particular the recover function of $p$ does not re-execute any line of the \texttt{T\&S}, contradicting the fact that $p$ writes to $Winner$ in line \ref{tas:write-to-winner}. Therefore, it must be that $p$ sets $R[p] \gets 3$, and this happens only after it writes to $Winner$. As a result, $q$ gets to line \ref{tas:rec:winner-not-overwrite} only after $p$ writes to $Winner$, and therefore does not write to $Winner$ in line \ref{tas:rec:write-winner}, in contradiction.
	
	Assume now there is a process $p$ writing to $Winner$ in line \ref{tas:rec:write-winner}. As just proved, no process can write to $Winner$ in line \ref{tas:write-to-winner}. Assume towards a contradiction there exists another process $q$ which writes to $Winner$ in line \ref{tas:rec:write-winner}. Without loss of generality, assume $p < q$. At time $t$ both processes are after executing line \ref{tas:start} and before executing line \ref{tas:rec:wait-lower-id}. Hence, in order to get to line \ref{tas:rec:write-winner} $q$ has to wait for $p$ to set $R[p] \gets 3$, that is, to complete its operation. This happens only after $p$ writes to $Winner$, thus in line \ref{tas:rec:check-winner} $q$ observes a value different then $null$ and does not write to $Winner$, in contradiction.
	
	We now prove that if the system is given enough time with no crash, then eventually some process writes to $Winner$. Assume towards a contradiction no process writes to $Winner$. If no operation crash after setting $R[p] \gets 2$ in line \ref{tas:set-R[p]-2}, then the first operation to execute line \ref{tas:tas-primitive} also writes to $Winner$, in contradiction. Thus, there must be such an operation, and it eventually executes \texttt{T\&S.RECOVER} and set $R[p] \gets 4$ in line \ref{tas:rec:set-R[p]-4}. A operation which does not execute line \ref{tas:rec:set-R[p]-4}, given enough time with no crash, eventually sets $R[p]$ to 3, and returns. As a result, after enough time with no crash of the system, and operation either completes, or after executing line \ref{tas:rec:set-R[p]-4}, and at least one operation satisfies the later. Let $p$ be the process with the smallest id satisfying the formar. Then, for any $i < p$ we have $R[i] \in \{0,3\}$, and for any $i > p$ we have $R[i] \in \{0,3,4\}$. Therefore, eventually $p$ complete the for loops in \texttt{T\&S.RECOVER}, and writes to $Winner$ in line \ref{tas:rec:write-winner}, in contradiction.
	
\end{proof}




\paragraph*{Using Recoverable Base Objects: an Example}

%Following the formal definition of RR-linearizability, a process needs to write the value it reads to $Res_p$ in order to implement a recoverable read. However, such an implementation is redundant and inefficient. In case a process crash before completing its read operation it can simply reissue it upon recovery.
%In general, operations that only read the status of an object and does not change it (more formally, operation that can be commute with any other operation by a different process), usually uses only read primitive (e.g., snapshot), or at least are implemented in a way such that if a process crash in the middle of an operation then reissue it does not affect the rest of the processes. In such cases, one can implement a recoverable version of the operation by having the \texttt{Recover} function restarting the operation.



%The implementation uses a single array $R$ of size $N$, the number of processes in the system. Each process $p$ has its own entry $R[p]$. For $INC$, a process $p$ simply adds 1 to the value in $R[p]$ by reading and then writing the updated value. The write is also the linearization point of the operation. For $READ$, process $p$ reads the entire array $R$ in a sequential manner, and sum up the values.

A \textit{Counter} object supports an \texttt{INC} operation that atomically increments its value and a \texttt{READ} operation. We start by describing a simple linearizable implementation of a \textit{Counter} object and then discuss the changes required for making it a recoverable \textit{Counter} satisfying CRL.
Each process $p$ has its own entry $R[p]$ in an array $R$ of integers, initialized to 0. To perform \texttt{INC}, $p$ simply increments $R[p]$. In the \texttt{READ} operation, $p$ reads all array entries, sums up the values and returns the sum.

\begin{claim}
	The \textit{Counter} algorithm described above is linearizable.
\end{claim}

\begin{proof}
	The correctness argument is as follows. Assume process $p$ completes a \texttt{READ} operation. Let $v$ be the value it read from $R[q]$. Since $R[q]$ is monotonically increasing, it must be that $R[q] \leq v$ immediately after the \texttt{READ}'s invocation and $R[q] \geq v$ immediately before the \texttt{READ}'s response. Therefore, at most $v$ \texttt{INC} operations by $q$ have been linearized before the \texttt{READ}'s invocation, and at least $v$ \texttt{INC} operations were linearized before the \texttt{READ}'s response. As this is true for any $q$, it implies that, as $p$ computes value $val$, then there are at most $val$ \texttt{INC} operations that were linearized before its \texttt{READ} invocation, and at least $val$ \texttt{INC} operations that were linearized before its \texttt{READ} response. In particular, there is a point during \texttt{READ}'s execution when exactly $val$ \texttt{INC} operations were linearized, so we linearize the \texttt{READ} operation at such a point.
\end{proof} 

\begin{algorithm}[b]%{Counter}

	\caption{recoverable Counter object $N$, program for process $p$}
	\label{alg:recoverable-counter}
	
	\hspace*{\algorithmicindent} \textbf{Shared variables:}
	R[N]: an array of recoverable read/write objects, init $[0,\ldots,0]$

	\begin{multicols}{2}
	\begin{algorithmic}[1]	
		\Procedure{\texttt{INC}()}{}
		\State $temp \gets R[p].\texttt{READ}$ \label{count:inc-start}
		\State $temp \gets temp+1$
		\State $R[p].\texttt{WRITE}(temp)$ \label{count:inc-invoke-write}
		\State \Return $ack$ \label{count:inc-return}
		\EndProcedure
		
		\Procedure{\texttt{INC.RECOVER}()}{}
		\If {$\text{LI}_p <$ \ref{count:inc-invoke-write} \label{count:inc-use-LI}}
			\State proceed from line \ref{count:inc-start}
		\Else{}
			\State \Return $ack$
		\EndIf
		\EndProcedure
		
		\columnbreak
		
		\Procedure{\texttt{READ}()}{}
		\State $val \gets 0$ \label{count:read-start}
		\For {$i$ from 1 to $N$}
			\State $val \gets val+R[i].\texttt{READ}$
		\EndFor
		\State $Res_p \gets val$
		\State \Return $val$
		\EndProcedure
		
		\Procedure{\texttt{READ.RECOVER}()}{}
		\State proceed from line \ref{count:read-start}
		\EndProcedure
	\end{algorithmic}
\end{multicols}
\end{algorithm}

Making this implementation recoverable necessitates equipping both operations with a \texttt{RECOVER} function. The pseudo-code of the recoverable implementation is shown by Algorithm~\ref{alg:recoverable-counter}.
As we described in Section \ref{section: Model}, our system model assumes that a recovery function $Op.\texttt{RECOVER}$ has access to $\text{LI}_p$ - a designated per-process non-volatile variable identifying the instruction of $Op$ that $p$ was about to execute when it incurred the crash that triggered $Op.\texttt{RECOVER}$. Our implementation of the \texttt{INC} operation, which we now describe, exemplifies how $\text{LI}_p$ is used.

The \texttt{INC} operation's write to $R[p]$ in line \ref{count:inc-invoke-write} is its linearization point. In order to ensure that $R[p]$ is incremented exactly once in each \texttt{INC} operation, we use an array $R$ of recoverable read/write objects, such as the one we described previously, instead of an array of (non-recoverable) read/write variables. Recall that our implementation of recoverable \texttt{WRITE} requires that distinct values will be written, but this imposes no overhead here since it is ensured by the counter's semantics.

Consider a crash that occurs between \texttt{INC}'s invocation and response.
If $p$ crashes inside \texttt{WRITE} (invoked by \texttt{INC} in line
\ref{count:inc-invoke-write}), then \texttt{WRITE} is the inner-most recoverable operation that was pending, so \texttt{WRITE.RECOVER} is invoked by the system and, once its recovery is completed, \texttt{INC} returns in line \ref{count:inc-return} (unless it crashes again). Otherwise, the system invokes \texttt{INC.RECOVER}, which uses $\text{LI}_p$ in line \ref{count:inc-use-LI} to determine whether the last crash inside \texttt{INC} occurred before line \ref{count:inc-invoke-write} -- in which case \texttt{INC} is re-executed, or after it -- in which case \texttt{INC.RECOVER} simply returns.





% \ref{count:inc-invoke-write}, then \texttt{INC.RECOVER} is invoked by the system. In this case, \texttt{INC.RECOVER} evaluates the condition of line \ref{count:inc-use-LI} as false and re-executes \texttt{INC}. If the crash was inside \texttt{WRITE}, \texttt{WRITE.RECOVER} is invoked and, once it returns, \texttt{INC} returns in line \ref{count:inc-return} (unless it fails again). Finally, if $p$ crashed when about to return in line \ref{}


%\color{blue} A crash after \texttt{WRITE} completes implies \texttt{INC.RECOVER} returns $ack$. The model assumes \texttt{INV.RECOVER} has an access to the last PC inside the \texttt{INC} code, where the crash took place, which is stored in LPC. So far, our implementations did not use this assumption. However, the \texttt{INC} requires a process to distinguish between a crash before and after \texttt{WRITE}, thus an access to LPC is needed. \color{black}

We chose to implement the counter's \texttt{READ} operation as strict recoverable. This was accomplished in our implementation by having \texttt{READ} write its response value, immediately before it returns, to a shared-memory variable $Res_p$, used by $p$ only. This ensures that a recoverable operation that invokes the counter's \texttt{READ} operation is able to access its response even if the process fails immediately after $N$.\texttt{READ} returns.


%For efficiency reasons, only \texttt{READ} is strict. The ability to re-execute \texttt{READ} in case of a crash, due to the fact it does not affect any other process, allows the use of primitives and not recoverable versions which have a lot of overhead. The only recoverable operation used is \texttt{WRITE} in line \ref{count:inc-invoke-write}.
Algorithm \ref{alg:recoverable-counter} demonstrates how recoverable base objects that satisfy the CRL condition can be used in our model for constructing more complex recoverable objects (satisfying the same condition) relatively easily. Modular constructions, such as that of Algorithm \ref{alg:recoverable-counter}, leverage the following key property guaranteed by CRL: base recoverable operations are guaranteed to be linearized correctly before they return, even in the presence of multiple crashes, allowing the implemented recoverable operation to proceed correctly.

%The above implementation is efficient in terms of the transformation to CRL form. It uses a single recoverable $WRITE$ operations, while the rest of the primitives are not replaced with a recoverable version. Also, the \texttt{Recover} functions are almost trivial - either restart or a \texttt{Recover} of the $WRITE$ operation. In terms of time and space complexity, the implementation is tight with both for the $INC$ and $READ$ operations, following Jayanti et. al lower bound \cite{DBLP:journals/siamcomp/JayantiTT00}.

\remove{%%%%%%%%%
\color{blue}
We assume a model in which the system has an access to the last program counter (PC) of the process upon recovery. Before invoking $Op.\texttt{Recover}$, the system updates a designated persistent variable with the last PC of the process, in case it is pointing the code of $Op$. This way, $Op.\texttt{Recover}$ can infer where in code the crash took place. This still leaves uncertainty regarding of whether the last instruction was executed.
\color{black}
}%%%%%%%%%%%

