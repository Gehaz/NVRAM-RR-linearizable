
\section{Recoverable Base Objects}
\label{section: Recoverable Base Objects}

We consider a model in which the program counter (PC) is stored in the non-volatile memory. This can be done either explicitly in the program, or implicitly by the operating system. In this model, upon recovery the last PC is available, and the system knows during what operation the process crash, and thus the proper \texttt{Recover} function is invoked. As a result, there is uncertainty regarding whether the last instruction was performed or not. We also assume the \texttt{Recover} function has an access to the last PC before the crash, or in other words, it is aware of at what line the crash took place.

The following example clarify why do we need the definition of recoverable object to holds even for the case of primitives.
Consider an object supporting a compare-and-swap (CAS) atomic operation. Assume a process $p$ is executing an operation $res \leftarrow C.CAS(old,new)$ followed by a crash. There are several options for at what exact time the crash took place, and each case raises a different problem.

In the standard crash model, a primitive operation is atomic and takes effect instantly in the history, that is, the response follows the invocation in the history, where no other step by any other process is allowed in between. Under the same definition, and assuming the process crash just after completing the CAS operation and before advancing the PC, there was a response step in the history, and thus the RR-linearizability does not require the process to recover the operation. However, the operation is still pending in some sense, as upon recovery the process does not know whether it took affect or not, since the PC still points the same line and $res$ content was erased.

Considering the response of the CAS operation to be at the time where the PC is being advanced solves the former problem. Nevertheless, what if the process crash just after the PC was changed? Again, the operation is not pending, so there is no need to recover it. In this case, upon recovery the process knows the operation was completed, since the PC no longer points to it. However, the process have no access to the response value that was stored in $res$, residing in the cache, and hence it may not be able to proceed its execution.

A recoverable version of CAS avoids the above problems. The operation considered to be complete only after both the CAS was linearized, and the response value is persistent in $Res_p$. Therefore, a crash after this point can cause no problem, as the process knows the operation was completed as well as have an access to the response value.

In the following section we present algorithms for implementing recoverable versions for well known primitives. A system equipped with such primitives can be used to implement any object in a recoverable way in the following manner: in case of a crash, the process will simply recover the last primitive operation along which the process crashed. Once the operation completes, the process can continue and execute the remaining code safely. Due to this observation we focus our attention to implementation of recoverable primitives.

The strongest progress property is bounded wait-free, that is, the number of steps a process takes when executing the recovery code in the absence of a failure is finite and bounded by a known constant (may be a function of n, the number of processes in the system), regardless of the other processes steps and the failures the process experienced so far. In addition, we would like the recovery code to use a finite number of variables.
Nonetheless, this progress property can not always be achieved, and therefore in some cases we weaken our demand to deadlock-freedom, that is, a process is allowed to wait in the recovery code, and if all processes takes enough steps then eventually the process will finish its recovery code.
%The fact that RR-linearizability allows us to swift the linearization point of an operation to after the crash is used to recover after a primitive failure.

The recoverable object definition requires the response value to be persistent for any operation. However, this requirement is inefficient in case of a trivial response as $ack$. In this case there is no point to save the response value in the non-volatile memory, as the only information relevant for the process is whether the operation was complete or not. For such an operation we define the response step to be at the point where to PC no longer points the code implementing the operation, and we do not persist the response value. This observation can be used for any operation with a trivial response, even though the recoverable object definition is general and does not handle these cases separately.

In addition, the question of having a crash along a \texttt{Recover} function needs to be address. One option is to assume a crash can not occur along executing a \texttt{Recover} function. In practice this might be reasonable to assume a short time of stability in the system following a crash. However, we wold like to have a stronger model, capable dealing with crash even along a \texttt{Recover} function. Notice also that a \texttt{Recover} function which uses only such recoverable primitives is itself recoverable.

In the following, we use the convention of capital letters names for shred variables and small letters for local variables. Also, a restart response of the \texttt{Recover} function implies the operation was not linearized and the process restart it (by moving back to the operation's first line). During the analysis we ignore the ABA problem, as this can be solved easily by augmenting any value with the writing process's id, and a sequential number (each process will have its own sequential number). This way we can guarantee no two identical values are used along any execution.

\paragraph*{Read}

Following the formal definition of RR-linearizability, a process needs to write the value it reads to $Res_p$ in order to implement a recoverable read. However, such an implementation is redundant and not efficient. In case the process crash before completing its read operation it can simply reissue it upon recovery.

In general, operations that only read the status of an object and does not change it (more formally, operation that can be commute with any other operation by a different process), usually uses only read primitive (e.g., snapshot), or at least implemented in a way such that if a process crash in the middle of an operation then reissue it does not affect the rest of the processes. In such cases, one can implement a recoverable version of the operation by having the \texttt{Recover} function reissuing the operation.

\paragraph*{Write}
For write, we "wrap" the atomic write with a mechanism which allows the process to conclude whether its write or a different write took place since the invocation. For that, process $p$ have a designated variable $R_p$ in the non-volatile memory. The same variable can be used for all write operations of process $p$.

\begin{algorithm}
	\caption{Write}\label{recoverable write}
	\begin{algorithmic}[1]	
		\Procedure{write}{}
		\State $temp \gets R$
		\State $R_p \gets temp$
		\State $R \gets val$
		\EndProcedure
		
		\Procedure{Recover}{}
		\If {$pc < 4$} \Return restart
		\EndIf
		\If {$R_p == R$} \Return restart
		\EndIf
		\State \Return $ack$
		\EndProcedure
	\end{algorithmic}
	\caption{R.write(val) by process $p$}
\end{algorithm}

For simplicity, we write the recovery code as a single instruction, although it needs to be written as several instructions, as it accesses two different locations in the shared memory. Since $R_p$ is designated to $p$ only, the point where $p$ reads $R$ determines the \texttt{Recover} function outcome.

The intuition for correctness is the following. If there was a write to $R$ between the two reads of $p$ (at line 2, and at the \texttt{Recover} function), then either this write is by $p$, and we can linearize it at the point where it took affect, or that there was a write by some other process, and we can linearize the write of $p$ just before it. Hence, the real write "overwrite" $p$'s write, and the rest of the processes can not distinguish between the two scenarios. Thus, in case of a failure before line 4 the operation will be aborted.

\begin{claim}
	The recoverable write implementation given in \ref{recoverable write} is RR-linearizable.
\end{claim}

\begin{proof}
	First notice that the \texttt{Recover} function only reads, thus repeating it does not effect the other processes. That is, if a process crash along the \texttt{Recover} function then restarting the function is indistinguishable from executing it once. Hence, the proof can ignore crashes along the \texttt{Recover} function. Also, notice that there is no waiting or locks used in the code, hence if a process given enough time (with no crash) then eventually it will finish the write operation (including the \texttt{Recover} function if needed). That is, the implementation is bounded wait-free.
	
	Consider a run $\alpha$, and let $p$ be a process executing operation $write(val)$ to variable $R$. If $p$ does not crash along the operation, then obviously $p$ write to $R$ once in line 4, and this is also the linearization point. Assume there is a crash along the operation. If the crash occurs before line 4 then $p$ did not wrote to $R$, and upon recovery it will restart the write operation. If the crash was in line 4 then $p$ wrote to $R_p$ the value it reads in line 2. There are two scenarios.
	
	Assume $R_p == R$, i.e., there was no write to $R$ between the time when $p$ reads $R$ in line 2, and in line 7. In particular, $p$ did not wrote to $R$ in line 4, since we assume all writes are distinct (and avoiding the ABA problem), and therefore it is safe to restart the write operation, as no process was affected by $p$'s operation so far. Assume now $R_p = R$, i.e., there was a write to $R$ between the time when $p$ read $R$ in line 2, and in line 7. If $p$ wrote to $R$ in line 4, then we can linearize the operation at this point. Otherwise, there is a write by a different process $q$. Linearizing $p$'s operation just before $q$ operation, causing $q$ to overwrite the value of $p$, generates a history which is indistinguishable to all process from the history where $p$ does not write at all. In any of these cases, there is a linearization point to the operation which respects the sequential specification of the object.
\end{proof}


\paragraph*{Compare-and-Swap}

A Compare-and-Swap (CAS) object supports the $cas(old,new)$ operation, which atomically compares the value stored in the object to old, and if they are equal, sets the value to be new. The operation returns the compression's result, that is, if the operation succeeded or failed. CAS object also support a read operation which returns the value stored in the object.

The main idea is to have the CAS stored also the if of a process who last committed a successful CAS. Thus, a process can inform a different process if its CAS operation was successful.
A process $p$ first reads the CAS object. If it observes a value different then $old$ it returns false. In such case, the operation is linearized at the linearization point of the read. Otherwise, $p$ informs the last process who committed a successful CAS that his operation was completed by writing to a designated location in the non-volatile memory. This way, if $p$ crash after a successful CAS operation, the next process which change the value of the CAS, first needs to inform $p$ his CAS was successful. Therefore, upon recovery $p$ can identify if its CAS took affect by seeing his value in $C$, or that some other process informed him about a success.

\begin{algorithm}
	\caption{Compare-and-Swap}\label{recoverable CAS}
	
	\hspace*{\algorithmicindent} \textbf{Shared variables:}
	\begin{itemize}
		\item C: compare-and-swap object, init $<null,null>$
		\item R[N][N]: two dimensions array, init $null$
	\end{itemize}
 
	\begin{algorithmic}[1]
		\Procedure{CAS}{}
		\State $<id,val> \gets C.read()$
		\If {$val \neq old$}
		\State \Return false
		\EndIf
		\If {$id \neq null$}
  		\State $R[id][p] \gets val$
		\EndIf
		\State $ret \gets C.cas(<id,val>, <p,new>)$
		\State $Res_p \gets ret$
		\State \Return $ret$
		\EndProcedure
		
		\Procedure{recover}{}
		\State Read C, R[p][$*$]
		\If {$<p,new>$ appears in C, or $new$ appears in R[p][$*$]}
		\State $Res_p \gets true$
		\State \Return $true$
		\Else {}
		\State \Return $restart$
		\EndIf
		\EndProcedure
	\end{algorithmic}
	\caption{C.cas(old,new) by process $p$}
\end{algorithm}


Following the code, a process crash before line 7 will restart its operation upon recovering, while a crash at line 7-8 (and before completing the operation) will depend on whether the CAS was successful. A key point in this implementation is that a fail CAS operation can be reissued anyway, since it does not effect other processes and thus reissuing it does not violate the sequential specification of the object.

\begin{claim}
	The recoverable CAS implementation given in \ref{recoverable CAS} is RR-linearizable.
\end{claim}

\begin{proof}
	First notice that the implementation is bounded wait-free, as there is no use with locks or waiting. Also, the CAS object is composed of two fields, an id of the last process to successfully write to C and a value. A key point is that linearizing a failed CAS operation does not effect the rest of the processes, that is, removing such an operation is indistinguishable to other processes.
	
	A process $p$ first reads the content of $C$. If the value in $C$ is different then $old$, then the process return false, and we can linearize the operation at the point of the read. Otherwise, $p$ will try to swap the content of $C$. Before that, it informs the last process who wrote to $C$ before the read that his write was successful, by writing in $R[id][p]$ the value it sees. We use a two dimensional array so that processes will not overwrite each other. Now the process can try and replace the value of $C$ with its own new value, while taking into consideration the id field of the CAS. Assuming $p$ does not crash along the CAS operation, a linearization point is set to the time of the cas primitive in line 7. Since we assumed no two identical values are written, a cas returning fail in line 7 means some other process did a successful cas between the read of $C$ in line 2 and the cas in line 7.
	 
	Assume process $p$ does crash along a cas operation. Since the \texttt{Recover} function only reads, or write to $Res_p$ which is a private variable of $p$, executing the \texttt{Recover} function does not effect other processes. Therefore, if a process crash along the \texttt{Recover} function, then restarting it is indistinguishable from executing it only once. Hence, it is enough to consider the point where $p$ executes the entire \texttt{Recover} function with no crash.
	
	If $p$ did not wrote to $C$, either because the crash was before line 7 or a failed cas at line 7, then the value new of $p$ will never be written to neither $C$ nor $R$. This follows from the fact that processes writes to $R$ only values they have seen in $C$. As a result, the \texttt{Recover} function of $p$ will return restart, and as mentioned earlier, a failed cas operation is indistinguishable from an execution where the operation is removed. Therefore, in both cases, considering the operation as not having a linearization point and restarting it does not violate the sequential specification of CAS.
	
	If $p$ did wrote to $C$, then the next process $q$ to successfully write to $C$ must also write to $R[p][q]$ the value which $p$ wrote to $C$. If $q$ executes line 2 before the successful cas of $p$, it follows that $p$ wrote to $C$ between line 2 and line 7 of $q$. Since we assumed every write is unique, it follows that the new value $p$ writes to $C$ is different then the old value that $q$ reads in line 2. In particular, the cas of $q$ in line 7 will fail (since $val$ is different from the current value stored in $C$), contradicting the assumption that $q$ is the next process after $p$ to perform a successful cas. Hence, it must be that $q$ executes line 2 after the cas of $p$ took effect, and in line 6 it writes to $R[p][q]$ the value it sees. To conclude, before replacing the value of $p$ stored in $C$ with a new value, it must be that some other process already wrote to $R[p][*]$ the new value of $p$. AS a result, when $p$ executes the \texttt{Recover} function, either it will see in $C$ the value it wrote, or that this value has been replaced with a new one, and therefore it will see in $R[p][*]$ the last value it wrote to $C$. In both cases, $p$ consider the cas operation as successful, and returns true. The linearization point of the operation is at the successful cas in line 7.
	 
\end{proof}

\paragraph*{Test-and-Set}

A Test-and-Set (TAS) object initially stores the value 0, and supports the t\&s operation which atomically change the value of the object to 1 and returns the previous value. A TAS object can be easily implemented using a single CAS object. However, we would like to support an implementation which only uses TAS and read/write primitives in case a process does not crash. It is possible to prove that given only TAS and read/write registers one can not implement a recoverable TAS which is also bounded wait-free, thus the \texttt{Recover} function will use waiting mechanism.

A process $p$ tries to win the TAS object, and the winning process writes its id into a designated variable $Winner$. Once a process writes to $Winner$ any process can recover from a crash by simply read $Winner$. Hence, the main difficulty is to make sure only one process writes to $Winner$, and this is the only process to return 0.

At the beginning of the \texttt{Recovery} function, process $p$ first announce it is recovering by writing 2 into $R[p]$. Then, in order to make sure any process running from this point on will return 1 (in case the crash occurred before the t\&s operation took effect) $p$ executes another t\&s operation on $T$. As discussed above, if $Winner$ was written to then $p$ can know if it is the process to win $T$ by comparing its id to the one in $T$. However, if $Winner$ was not written to, all crashed processes needs to agree on the winner. For that, we use a CAS object for simplicity, although any recoverable leader election algorithm can be used here (for example, one that only uses reads and writes). Notice that there is no need to use recoverable CAS here, since in a crash along the \texttt{Recovery} function, the process can simply restart the function.

Once $p$ wins the CAS, it is the only crashed process to win, and therefore it is the candidate to win the TAS object. However, it might be that some other process already won the TAS, but yet to write to $Winner$. To overcome this scenario, $p$ waits for every active process to either finish its t\&s operation, or to start the \texttt{Recovery} function. We know that any process who will run starting from this point will lose the TAS object, and the CAS object (in case of a crash). Thus, if after the for loop no process wrote to $Winner$ then $p$ can safely announce itself as the winner. Otherwise, $p$ lost to some other active process, and this process wrote to $Winner$ since it won the TAS object in line 3.


\begin{algorithm}
	\caption{Test-and-Set}\label{recoverable TAS}
	
	\hspace*{\algorithmicindent} \textbf{Shared variables:}
	\begin{itemize}
		\item T: Test-and-Set object, init $0$
		\item C: Compare-and-Swap object, init $null$
		\item R[N]: an array, init $0$
		\item Winner: a register, init $null$
	\end{itemize}
	
	\begin{algorithmic}[1]
		\Procedure{T\&S}{}
		\State $R[p] \gets 1$
		\State $ret \gets T.t\&s()$
		\If {$ret = 0$}
			\State $Winner \gets p$
		\EndIf
		\State $Res_p \gets ret$
		\State $R[p] \gets 0$
		\State \Return $ret$
		\EndProcedure
		
		\Procedure{recover}{}
		\State $R[p] \gets 2$
		\State $T.t\&s()$
		\If {$Winner \neq null$}
			\State $ret \gets (Winner == p)$
			\State $Res_p = ret$
			\State \Return $ret$
		\EndIf
		\State $C.cas(null,p)$
		\If {$C \neq p$}
			\State $Res_p \gets 1$
			\State \Return $1$
		\EndIf
		\For {$i$ from $0$ to $N$}
			\State $await(R[p] \neq 1)$
		\EndFor
		\If {$Winner = null$}
			\State $Winner \gets p$
		\EndIf
		\State $ret \gets (Winner == p)$
		\State $Res_p = ret$
		\State \Return $ret$
		\EndProcedure
	\end{algorithmic}
	\caption{T.t\&s() by process $p$}
\end{algorithm}